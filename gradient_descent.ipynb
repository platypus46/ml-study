{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사 하강법(Gradient Descent)  \n",
    "- 배치 경사 하강법\n",
    "- 확률적 경사 하강법\n",
    "- 미니배치 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다항식 생성\n",
    "\n",
    "**𝑦 ̂=𝜃_0+𝜃_1 𝑥_1+𝜃_2 𝑥_2+⋯+𝜃_𝑛 𝑥_𝑛**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다항식: (0.5*X1)+(0.3*X2)+(0.7*X3)+0.6\n",
      "시작 다항식: (0.6237173954410795*X1)+(0.7499232899117962*X2)+(0.3768265047718866*X3)+0.13898882549075142\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "x1 = np.random.rand(100)\n",
    "x2 = np.random.rand(100)\n",
    "x3 = np.random.rand(100)\n",
    "\n",
    "#다항식 정의\n",
    "y=0.5*x1+0.3*x2+0.7*x3+0.6\n",
    "\n",
    "w1 = np.random.uniform(low=-1.0, high=1.0)\n",
    "w2 = np.random.uniform(low=-1.0, high=1.0)\n",
    "w3 = np.random.uniform(low=-1.0, high=1.0)\n",
    "\n",
    "bias = np.random.uniform(low=-1.0, high=1.0)\n",
    "\n",
    "print(\"다항식: (0.5*X1)+(0.3*X2)+(0.7*X3)+0.6\")\n",
    "print(f\"시작 다항식: ({w1}*X1)+({w2}*X2)+({w3}*X3)+{bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 경사 하강법(Batch Gradient Descent)\n",
    "\n",
    "1. 전체 학습 데이터를 하나의 batch로 묶어 학습시키는 경사하강법을 말한다.    \n",
    "2. 일반적으로 경사 하강법을 말한다면 배치 경사 하강법을 의미한다.  \n",
    "\n",
    "**장점**  \n",
    "* 전체 학습 데이터에 대해 한번의 연산이 시행되기 때문에 연산 횟수가 적다.\n",
    "* 전체 데이터에 대해 그래디언트를 계산하여 진행하기 때문에, 수렴이 안정적으로 진행된다.(장점이자 단점:local minima 발생 가능성이 증가함)  \n",
    "  \n",
    "**단점**\n",
    "* local minima 문제에 빠지기 쉽다.\n",
    "* 전체 데이터를 한 번에 처리해야하기 때문에 많은 메모리가 필요하다.\n",
    "\n",
    "#### 𝜃^((𝑛𝑒𝑥𝑡 𝑠𝑡𝑒𝑝))=𝜃−𝜂∇_𝜃 𝑀𝑆𝐸(𝜃)  \n",
    "* 기울기가 양수라면 음의 방향으로 x를 옮기고 기울기가 음수라면 양의 방향으로 x를 옮긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>clear()← 편의상 초기화함수를 만들었습니다.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    x1 = np.random.rand(100)\n",
    "    x2 = np.random.rand(100)\n",
    "    x3 = np.random.rand(100)\n",
    "    \n",
    "    y=0.5*x1+0.3*x2+0.7*x3+0.6\n",
    "    w1 = np.random.uniform(low=-1.0, high=1.0)\n",
    "    w2 = np.random.uniform(low=-1.0, high=1.0)\n",
    "    w3 = np.random.uniform(low=-1.0, high=1.0)\n",
    "    \n",
    "    bias = np.random.uniform(low=-1.0, high=1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 w1=  0.7888048891846277 w2=  0.8827749229682258 w3=  0.6000135051280101 bias=  0.5010159578166877 error=  0.1588294379116109\n",
      "epoch 10 w1=  0.6338108537682828 w2=  0.5263795570271584 w3=  0.6582659833031241 bias=  0.47863629584535794 error=  0.009268771110196859\n",
      "epoch 20 w1=  0.5721611907341524 w2=  0.39706279801997035 w3=  0.6962116047134397 bias=  0.5208067543977063 error=  0.0015805270347264188\n",
      "epoch 30 w1=  0.5406593883077175 w2=  0.34428725217893363 w3=  0.7090555071770006 bias=  0.5519965789570817 error=  0.0003902956831623779\n",
      "epoch 40 w1=  0.5233217374858541 w2=  0.32126493022425534 w3=  0.7108233493430988 bias=  0.5710212362288867 error=  0.0001144161639667147\n",
      "epoch 50 w1=  0.5135600180414222 w2=  0.31070932122120165 w3=  0.7090148707857701 bias=  0.582381429418219 error=  3.782061999287842e-05\n",
      "epoch 60 w1=  0.5079863506121942 w2=  0.3056395091761132 w3=  0.7066010580911658 bias=  0.5892120768825869 error=  1.3488398153833027e-05\n",
      "epoch 70 w1=  0.504759859921235 w2=  0.3030900206687192 w3=  0.7045373736633016 bias=  0.593359310007247 error=  5.017252215232502e-06\n",
      "epoch 80 w1=  0.5028662279303758 w2=  0.30175029591632613 w3=  0.7030096503355352 bias=  0.5958970202795315 error=  1.9067947008972444e-06\n",
      "학습 완료:  w1=  0.5020199625591198 w2=  0.3011947748563232 w3=  0.7022278168151889 bias=  0.5970664169059794 error=  9.751770188980477e-07\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "clear()\n",
    "\n",
    "#학습 횟수\n",
    "epoch=1000\n",
    "\n",
    "#학습률\n",
    "lr=0.5\n",
    "\n",
    "for i in range(epoch):\n",
    "    predict=w1*x1+w2*x2+w3*x3+bias\n",
    "    \n",
    "    #MSE\n",
    "    error = ((predict - y)**2).mean()\n",
    "    \n",
    "    w1 = w1 - 2*lr*((predict - y)*x1).mean()\n",
    "    w2 = w2 - 2*lr*((predict - y)*x2).mean()\n",
    "    w3 = w3 - 2*lr*((predict - y)*x3).mean()\n",
    "    \n",
    "    bias = bias - 2*lr*(predict - y).mean()\n",
    "    \n",
    "    if i%10 == 0:        \n",
    "        print(\"epoch\", i, \"w1= \", w1 , \"w2= \", w2, \"w3= \", w3,\"bias= \", bias, \"error= \", error)\n",
    "        \n",
    "    if error < 0.000001:\n",
    "        break\n",
    "        \n",
    "print(\"학습 완료: \",\"w1= \", w1 , \"w2= \", w2, \"w3= \", w3,\"bias= \", bias, \"error= \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법(Stochastic Gradient Descent)\n",
    "1.진행되는 step마다 한 개의 샘플을 무작위로 선택하고 선택된 샘플에 대한 기울기를 계산한다.  \n",
    "\n",
    "**장점**  \n",
    "* 매우 적은 데이터셋을 처리하기 때문에 처리속도가 빠르다.  \n",
    "* local minima 문제를 해결하기 용이하다.  \n",
    "\n",
    "**단점**  \n",
    "* 불안정하게 수렴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1000 | w1=  0.5023676025092302 | w2=  0.3016448630384415 | w3=  0.7026010675193107 | bias=  0.5982504196253167 | error=  0.13645976547692393\n",
      "학습 완료:  | w1=  0.5023676025092302 | w2=  0.3016448630384415 | w3=  0.7026010675193107 | bias=  0.5982504196253167 | error=  0.13645976547692393\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "clear()\n",
    "\n",
    "epoch=1000\n",
    "lr=0.5\n",
    "\n",
    "for i in range(epoch):\n",
    "    x1_sgd = np.random.choice(x1)\n",
    "    x2_sgd = np.random.choice(x2)\n",
    "    x3_sgd = np.random.choice(x3)\n",
    "    y_sgd = 0.5*x1_sgd + 0.3*x2_sgd + 0.7*x3_sgd + 0.6\n",
    "    \n",
    "  \n",
    "    predict_sgd = w1*x1_sgd + w2*x2_sgd + w3*x3_sgd + bias\n",
    "    \n",
    "  \n",
    "    w1 = w1 - 2*lr*((predict_sgd - y_sgd)*x1_sgd)\n",
    "    w2 = w2 - 2*lr*((predict_sgd - y_sgd)*x2_sgd)\n",
    "    w3 = w3 - 2*lr*((predict_sgd - y_sgd)*x3_sgd)\n",
    "    bias = bias - 2*lr * (predict_sgd - y_sgd)\n",
    "    \n",
    "\n",
    "    predict = w1*x1 + w2*x2 + w3 + bias\n",
    "    error = ((y - predict)**2).mean()\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(\"| epoch \", epoch,\"| w1= \", w1, \"| w2= \", w2, \"| w3= \", w3,\"| bias= \", bias, \"| error= \", error)\n",
    "        \n",
    "    if i < 0.000001:\n",
    "        break\n",
    "        \n",
    "print(\"학습 완료: \",\"| w1= \", w1 , \"| w2= \", w2, \"| w3= \", w3,\"| bias= \", bias, \"| error= \", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니 배치 경사하강법(Mini-Batch Stochastic Gradient Descent)\n",
    "1.전체 데이터를 N등분하고 각각의 학습 데이터를 배치 방식으로 학습한다.\n",
    "\n",
    "**특징**\n",
    "- bgd와 sgd의 장점을 결합한 형태\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.48751358474493944 | w2=  0.28083765133854954 | w3=  0.6786188332881772 | bias=  0.5649572695735684 | error=  0.0039638346717659175\n",
      "iteration  1 | w1=  0.4896338891764221 | w2=  0.2905136680022561 | w3=  0.6866008849816067 | bias=  0.5821439878711558 | error=  0.0012519753372817622\n",
      "iteration  2 | w1=  0.4652464968568942 | w2=  0.28599169983616796 | w3=  0.676556933243502 | bias=  0.5600511255269344 | error=  0.006034865569841523\n",
      "iteration  3 | w1=  0.4733150284618749 | w2=  0.3028735088174844 | w3=  0.6894101940843715 | bias=  0.5855313902891923 | error=  0.0010877187870094486\n",
      "iteration  4 | w1=  0.45699064755753516 | w2=  0.2971923011392916 | w3=  0.685301699275525 | bias=  0.5685383254183647 | error=  0.004001539684372399\n",
      "iteration  5 | w1=  0.4613838071940182 | w2=  0.3068211663610783 | w3=  0.697497023407061 | bias=  0.5888358424025933 | error=  0.0009191649179891212\n",
      "iteration  6 | w1=  0.4472177079097017 | w2=  0.2967774724614536 | w3=  0.6868762044504136 | bias=  0.5685482990852944 | error=  0.004598648807486619\n",
      "iteration  7 | w1=  0.45012032296899157 | w2=  0.30634517219565816 | w3=  0.696399323048397 | bias=  0.5833614300070546 | error=  0.0018042163930557203\n",
      "iteration  8 | w1=  0.4367573052617939 | w2=  0.29538444499179034 | w3=  0.6834771777289192 | bias=  0.5668179558047124 | error=  0.00603411473114633\n",
      "iteration  9 | w1=  0.4453125264412686 | w2=  0.31102689040193165 | w3=  0.6960843326700366 | bias=  0.5919623519127222 | error=  0.0012614469639128506\n",
      "epoch:  1\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.4401582182484434 | w2=  0.30359144722155573 | w3=  0.6886447319779779 | bias=  0.5815549872905906 | error=  0.00302943130671502\n",
      "iteration  1 | w1=  0.4394168881507303 | w2=  0.30478118911491225 | w3=  0.6908639160564328 | bias=  0.5859104005985885 | error=  0.002465120158756988\n",
      "iteration  2 | w1=  0.4316926461634029 | w2=  0.30380739966595105 | w3=  0.6894194309527834 | bias=  0.5812112660130945 | error=  0.0035461717864782053\n",
      "iteration  3 | w1=  0.4317717641811301 | w2=  0.3067286687149195 | w3=  0.6919204323892733 | bias=  0.5862265971847084 | error=  0.002728372802402191\n",
      "iteration  4 | w1=  0.4284111395081349 | w2=  0.30589866723930936 | w3=  0.6948947479191702 | bias=  0.5868740278383046 | error=  0.002741318114547007\n",
      "iteration  5 | w1=  0.4274053248198065 | w2=  0.30567948136200107 | w3=  0.6960725378377344 | bias=  0.589196045713124 | error=  0.002531147958913084\n",
      "iteration  6 | w1=  0.42412879842013823 | w2=  0.3036705728462878 | w3=  0.6954262666226965 | bias=  0.5866127614348084 | error=  0.003102422864694823\n",
      "iteration  7 | w1=  0.4224919392548366 | w2=  0.3050508455591609 | w3=  0.6968463606287448 | bias=  0.5877679880583053 | error=  0.002943747150272053\n",
      "iteration  8 | w1=  0.419463865701681 | w2=  0.30234476688614353 | w3=  0.694051108053377 | bias=  0.5849994571390533 | error=  0.0037318201862706333\n",
      "iteration  9 | w1=  0.42114676997961403 | w2=  0.30658672432232614 | w3=  0.6978321552198773 | bias=  0.591894424086611 | error=  0.002518455443757625\n",
      "epoch:  2\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.4199072713674851 | w2=  0.30529438062130715 | w3=  0.6969287103965588 | bias=  0.5907260280787223 | error=  0.00279930210841777\n",
      "iteration  1 | w1=  0.4182354487377844 | w2=  0.30398095454810614 | w3=  0.6965020125837487 | bias=  0.5901110867993844 | error=  0.0030441074082529817\n",
      "iteration  2 | w1=  0.416035052974333 | w2=  0.3041492396570256 | w3=  0.6970811814142003 | bias=  0.5902523271363782 | error=  0.003128367706687362\n",
      "iteration  3 | w1=  0.41482380752783043 | w2=  0.3040620211877709 | w3=  0.6970645751899107 | bias=  0.590478746033425 | error=  0.0031876730763535886\n",
      "iteration  4 | w1=  0.41449013213897434 | w2=  0.304249585902737 | w3=  0.6997172586697132 | bias=  0.5931877380102791 | error=  0.002795220997635356\n",
      "iteration  5 | w1=  0.4131844494649968 | w2=  0.3029265418932305 | w3=  0.6989816815912748 | bias=  0.5924649129517129 | error=  0.0030422740246143437\n",
      "iteration  6 | w1=  0.4124763282018565 | w2=  0.302650844591275 | w3=  0.6996985475270756 | bias=  0.592943200344783 | error=  0.0030143507431805057\n",
      "iteration  7 | w1=  0.4110191632869702 | w2=  0.30266877244424667 | w3=  0.6996452808830791 | bias=  0.5922330607493297 | error=  0.003178193652037028\n",
      "iteration  8 | w1=  0.4100606815157745 | w2=  0.30173767868607704 | w3=  0.6987941600592134 | bias=  0.5917848440290258 | error=  0.0033785895417707385\n",
      "iteration  9 | w1=  0.41066913636405306 | w2=  0.30356041972316855 | w3=  0.70033717641275 | bias=  0.594707257752307 | error=  0.0028833040911043105\n",
      "epoch:  3\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.410052927804854 | w2=  0.30292047338223355 | w3=  0.699865475153563 | bias=  0.5941795804307775 | error=  0.0030247425351691577\n",
      "iteration  1 | w1=  0.4093467856892228 | w2=  0.3024310209293792 | w3=  0.6996369709294009 | bias=  0.59429377235706 | error=  0.003092687381502781\n",
      "iteration  2 | w1=  0.4080512926442932 | w2=  0.30230704606099834 | w3=  0.6995797773905539 | bias=  0.5940163257515327 | error=  0.0032114802328648572\n",
      "iteration  3 | w1=  0.4076551249310968 | w2=  0.3025015062060745 | w3=  0.6997363418137035 | bias=  0.5945598868246549 | error=  0.0031653885317370657\n",
      "iteration  4 | w1=  0.4074202794387563 | w2=  0.30253627924568743 | w3=  0.7008753105382749 | bias=  0.5956982184543281 | error=  0.0030080625266728643\n",
      "iteration  5 | w1=  0.4067310214146791 | w2=  0.30181099420319474 | w3=  0.7004183777259287 | bias=  0.5953515135098266 | error=  0.003142257360875532\n",
      "iteration  6 | w1=  0.4064362984170386 | w2=  0.30168742298938683 | w3=  0.7008066055173733 | bias=  0.5956894420594852 | error=  0.0031131419022049807\n",
      "iteration  7 | w1=  0.4057286300227976 | w2=  0.3016814174993262 | w3=  0.7007350579743558 | bias=  0.5953361528855204 | error=  0.003196919555735012\n",
      "iteration  8 | w1=  0.40510248285120515 | w2=  0.3010818848912402 | w3=  0.7001600677611661 | bias=  0.5949879951053373 | error=  0.0033322191324275385\n",
      "iteration  9 | w1=  0.40562342809154894 | w2=  0.30222020373828773 | w3=  0.7010617311767838 | bias=  0.5968693194694827 | error=  0.0030135219007532588\n",
      "epoch:  4\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.4051392710089298 | w2=  0.30154289439165577 | w3=  0.7004378490086426 | bias=  0.5961036378893679 | error=  0.003181779292570814\n",
      "iteration  1 | w1=  0.4050529036443823 | w2=  0.3016409942644049 | w3=  0.7005366338306686 | bias=  0.5968482881182009 | error=  0.0031051108316987484\n",
      "iteration  2 | w1=  0.4040952155700497 | w2=  0.30134694714048127 | w3=  0.7001389037940716 | bias=  0.5962145860017498 | error=  0.0032635176954005506\n",
      "iteration  3 | w1=  0.4041335988543484 | w2=  0.3017067782177379 | w3=  0.7004330293917157 | bias=  0.5969519096708523 | error=  0.0031559618166234166\n",
      "iteration  4 | w1=  0.40388962278554347 | w2=  0.301643062009355 | w3=  0.7008515191670919 | bias=  0.5972736944940935 | error=  0.0031211853098960882\n",
      "iteration  5 | w1=  0.40353817787659063 | w2=  0.30126075940438285 | w3=  0.700614403730955 | bias=  0.5971647885057543 | error=  0.003184389403930546\n",
      "iteration  6 | w1=  0.4033992054396016 | w2=  0.3011844776470195 | w3=  0.7008172310959339 | bias=  0.5973647315298888 | error=  0.00316659326637783\n",
      "iteration  7 | w1=  0.40305346643174866 | w2=  0.30116742170800576 | w3=  0.7007643157586351 | bias=  0.597189195289308 | error=  0.003209491795008473\n",
      "iteration  8 | w1=  0.4026577783260674 | w2=  0.3007865086941731 | w3=  0.7003953154890268 | bias=  0.5969521026425951 | error=  0.003296403248835233\n",
      "iteration  9 | w1=  0.40302995677127523 | w2=  0.30145814900850854 | w3=  0.7009243047803394 | bias=  0.5981109469177543 | error=  0.0030999766940002955\n",
      "epoch:  5\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.40270208278905595 | w2=  0.30093869641034665 | w3=  0.7004299452633062 | bias=  0.5974921976871129 | error=  0.0032310796261246105\n",
      "iteration  1 | w1=  0.4027791073649671 | w2=  0.301136032335753 | w3=  0.7005813695228952 | bias=  0.598193587552224 | error=  0.0031406965584297604\n",
      "iteration  2 | w1=  0.4021595732857973 | w2=  0.30087882380760983 | w3=  0.7002213992467703 | bias=  0.5976657378424531 | error=  0.003263168989012371\n",
      "iteration  3 | w1=  0.4022650040352145 | w2=  0.30115188453141384 | w3=  0.7004511486224195 | bias=  0.5982174188444996 | error=  0.0031773702708687407\n",
      "iteration  4 | w1=  0.402111496236096 | w2=  0.3010940015526373 | w3=  0.7006364384343108 | bias=  0.5983347742367412 | error=  0.0031687064723910667\n",
      "iteration  5 | w1=  0.40190134547126144 | w2=  0.30084774209504067 | w3=  0.7004736046027261 | bias=  0.5982501130256516 | error=  0.0032104818830100586\n",
      "iteration  6 | w1=  0.4018608445564592 | w2=  0.30082342372191767 | w3=  0.7006192119341265 | bias=  0.5984258396762949 | error=  0.003189384489309876\n",
      "iteration  7 | w1=  0.4016599831323351 | w2=  0.3007809363917638 | w3=  0.7005582185541234 | bias=  0.5982857834388577 | error=  0.0032211582710817204\n",
      "iteration  8 | w1=  0.4014452986322973 | w2=  0.30056723630297766 | w3=  0.7003582218068306 | bias=  0.5981776252198742 | error=  0.003266407686768772\n",
      "iteration  9 | w1=  0.40166849682377154 | w2=  0.30093318729807716 | w3=  0.7006495488229405 | bias=  0.5988337058279493 | error=  0.0031555998906179807\n",
      "epoch:  6\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.4014704614840875 | w2=  0.3006014174801277 | w3=  0.7003343982516861 | bias=  0.5984399459856118 | error=  0.003238692048025906\n",
      "iteration  1 | w1=  0.4015525613736436 | w2=  0.30075295502681787 | w3=  0.7004460515905101 | bias=  0.5989279112400424 | error=  0.0031729631460515224\n",
      "iteration  2 | w1=  0.4011819476116333 | w2=  0.30057580649638477 | w3=  0.700199426844866 | bias=  0.5985822497067355 | error=  0.0032518597253261713\n",
      "iteration  3 | w1=  0.4012624863387853 | w2=  0.30074377978703015 | w3=  0.7003435530339419 | bias=  0.5989283726071922 | error=  0.0031973692519409232\n",
      "iteration  4 | w1=  0.40118196937358985 | w2=  0.300708107056517 | w3=  0.7004430323942413 | bias=  0.5989959016076766 | error=  0.0031923770205779705\n",
      "iteration  5 | w1=  0.4010482649423178 | w2=  0.30054194135092277 | w3=  0.7003246907563009 | bias=  0.5989181242821839 | error=  0.003222552446560059\n",
      "iteration  6 | w1=  0.4010495553233297 | w2=  0.30054300673701606 | w3=  0.7004317808094978 | bias=  0.59906244608204 | error=  0.003202692642146385\n",
      "iteration  7 | w1=  0.40092474714265286 | w2=  0.3004981576828966 | w3=  0.7003764116865144 | bias=  0.5989515602735958 | error=  0.0032265501949890283\n",
      "iteration  8 | w1=  0.4008120466281605 | w2=  0.3003814482745819 | w3=  0.7002719503723351 | bias=  0.5989109196310151 | error=  0.003248851339042715\n",
      "iteration  9 | w1=  0.4009412229120245 | w2=  0.3005811002741648 | w3=  0.7004316865192564 | bias=  0.5992794653619885 | error=  0.0031868715402851478\n",
      "epoch:  7\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.4008238035426995 | w2=  0.3003780777723508 | w3=  0.7002393441651926 | bias=  0.5990404244389574 | error=  0.0032373303346221486\n",
      "iteration  1 | w1=  0.40088547323714313 | w2=  0.30047988911668744 | w3=  0.7003119834711652 | bias=  0.5993563066357379 | error=  0.0031940376031415903\n",
      "iteration  2 | w1=  0.4006648469076784 | w2=  0.3003650593365611 | w3=  0.7001525083817647 | bias=  0.5991394321800507 | error=  0.003243190598184939\n",
      "iteration  3 | w1=  0.4007194345922625 | w2=  0.3004670007474959 | w3=  0.7002407545530375 | bias=  0.5993523276407707 | error=  0.0032094731385578696\n",
      "iteration  4 | w1=  0.40067637210886786 | w2=  0.3004455295258013 | w3=  0.7002957373688982 | bias=  0.599392384749956 | error=  0.003206438320795827\n",
      "iteration  5 | w1=  0.40059277989416414 | w2=  0.30033807079178343 | w3=  0.7002157450672979 | bias=  0.5993344921419058 | error=  0.0032267070187433\n",
      "iteration  6 | w1=  0.400604105522156 | w2=  0.30034516561859165 | w3=  0.7002880147484745 | bias=  0.5994370922721558 | error=  0.003211828662649461\n",
      "iteration  7 | w1=  0.4005275740187761 | w2=  0.30031063864292723 | w3=  0.7002471282235044 | bias=  0.599359955230307 | error=  0.0032280453172215612\n",
      "iteration  8 | w1=  0.4004656494927585 | w2=  0.3002446159061247 | w3=  0.7001898892961279 | bias=  0.5993445191122189 | error=  0.0032396900953220726\n",
      "iteration  9 | w1=  0.40054230946291236 | w2=  0.30035786234795425 | w3=  0.7002803589811777 | bias=  0.5995578238175857 | error=  0.0032039143504605946\n",
      "epoch:  8\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.400471518293619 | w2=  0.30023278843117024 | w3=  0.700161684391265 | bias=  0.5994107350796435 | error=  0.0032349109028545426\n",
      "iteration  1 | w1=  0.4005147720330232 | w2=  0.3003000109830817 | w3=  0.7002085349001739 | bias=  0.5996127786743259 | error=  0.003206855558834794\n",
      "iteration  2 | w1=  0.40038138600205786 | w2=  0.30022658226803356 | w3=  0.7001063145467584 | bias=  0.5994761634777044 | error=  0.003237602358032788\n",
      "iteration  3 | w1=  0.4004180546908601 | w2=  0.3002898776707783 | w3=  0.7001612678345082 | bias=  0.5996087386770177 | error=  0.0032164556084515778\n",
      "iteration  4 | w1=  0.4003933198872656 | w2=  0.3002764260008177 | w3=  0.7001911845849315 | bias=  0.599630598370753 | error=  0.003214964320129223\n",
      "iteration  5 | w1=  0.40034211076506426 | w2=  0.30020926405325543 | w3=  0.7001400271557114 | bias=  0.5995924201381687 | error=  0.0032278271238822304\n",
      "iteration  6 | w1=  0.40035280841454135 | w2=  0.3002157534580632 | w3=  0.7001861661742121 | bias=  0.5996597795425579 | error=  0.003217833116001323\n",
      "iteration  7 | w1=  0.40030659476547203 | w2=  0.3001922700694489 | w3=  0.7001588193351451 | bias=  0.5996098930167334 | error=  0.003228212250444235\n",
      "iteration  8 | w1=  0.4002709855401705 | w2=  0.30015362298854215 | w3=  0.7001259193052443 | bias=  0.5996033724382476 | error=  0.0032347049888533917\n",
      "iteration  9 | w1=  0.4003174135592755 | w2=  0.30021977666566413 | w3=  0.7001786421068908 | bias=  0.5997297721052911 | error=  0.0032135334019397542\n",
      "epoch:  9\n",
      "--------------------------------------------------\n",
      "iteration  0 | w1=  0.40027427490520584 | w2=  0.3001423526626114 | w3=  0.700104995478668 | bias=  0.5996385461937431 | error=  0.0032327087130655085\n",
      "iteration  1 | w1=  0.4003034347829834 | w2=  0.30018604390305836 | w3=  0.7001350467968486 | bias=  0.5997665983953988 | error=  0.0032147452814154454\n",
      "iteration  2 | w1=  0.4002221813099251 | w2=  0.30013959303770205 | w3=  0.7000702036894919 | bias=  0.5996807777478441 | error=  0.0032339453091348486\n",
      "iteration  3 | w1=  0.40024630352227736 | w2=  0.30017903723647027 | w3=  0.7001045066170514 | bias=  0.5997633692889147 | error=  0.0032206896665643013\n",
      "iteration  4 | w1=  0.40023160107712646 | w2=  0.30017054604448085 | w3=  0.7001209487277918 | bias=  0.5997751019743666 | error=  0.003220019957431655\n",
      "iteration  5 | w1=  0.4002004047499318 | w2=  0.30012908076570083 | w3=  0.7000889506873719 | bias=  0.5997509162663393 | error=  0.0032280180471446745\n",
      "iteration  6 | w1=  0.40020841066327256 | w2=  0.3001338443781498 | w3=  0.7001178126375456 | bias=  0.5997937783845071 | error=  0.0032215782431416567\n",
      "iteration  7 | w1=  0.4001805297365622 | w2=  0.3001185769087586 | w3=  0.7001002144157349 | bias=  0.5997623335722796 | error=  0.003228081290726848\n",
      "iteration  8 | w1=  0.40015963682583294 | w2=  0.3000956183410278 | w3=  0.700080912179431 | bias=  0.5997594447219541 | error=  0.0032318110794038097\n",
      "iteration  9 | w1=  0.40018787090687036 | w2=  0.3001347665748541 | w3=  0.7001120814297804 | bias=  0.5998350647076123 | error=  0.0032191554676989555\n",
      "학습 완료:  | w1=  0.40018787090687036 | w2=  0.3001347665748541 | w3=  0.7001120814297804 | bias=  0.5998350647076123 | error=  0.0032191554676989555\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "clear()\n",
    "\n",
    "epoch=10\n",
    "lr=0.5\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"epoch: \", i)\n",
    "    print(\"-\"*50)\n",
    "    batch_size = 10\n",
    "    batch_number = 100/10\n",
    "    start = 0\n",
    "    end = 10\n",
    "    \n",
    "    for iteration in range(int(batch_number)):\n",
    "        x1_batch = x1[start: end]\n",
    "        x2_batch = x2[start: end]\n",
    "        x3_batch = x3[start: end]\n",
    "        y_batch = 0.4*x1_batch + 0.3*x2_batch + 0.7*x3_batch + 0.6\n",
    "        \n",
    "        start += 10\n",
    "        end += 10\n",
    "\n",
    "        predict_batch = w1*x1_batch + w2*x2_batch + w3*x3_batch + bias\n",
    "\n",
    "   \n",
    "        w1 = w1 - 2*lr*((predict_batch - y_batch)*x1_batch).mean()\n",
    "        w2 = w2 - 2*lr*((predict_batch - y_batch)*x2_batch).mean()\n",
    "        w3 = w3 - 2*lr*((predict_batch - y_batch)*x3_batch).mean()\n",
    "        bias = bias - 2*lr * (predict_batch - y_batch).mean()\n",
    "\n",
    "        predict = w1*x1 + w2*x2 + w3*x3 + bias\n",
    "        error = ((y - predict)**2).mean()\n",
    "\n",
    "        print(\"iteration \", iteration,\"| w1= \", w1, \"| w2= \", w2, \"| w3= \", w3,\"| bias= \", bias, \"| error= \", error)\n",
    "\n",
    "    if error < 0.000001:\n",
    "            break\n",
    "print(\"학습 완료: \",\"| w1= \", w1 , \"| w2= \", w2, \"| w3= \", w3,\"| bias= \", bias, \"| error= \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
